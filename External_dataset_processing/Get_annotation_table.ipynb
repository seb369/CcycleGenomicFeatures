{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating combined tables of genome annotations for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "workdir = '/home/sam/FullCyc_metagenome/Other_studies_comp/redo_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_list = ['Avena_rhizosphere',  'biocharSIP',  'DeepSIP',\n",
    "              'rainfall',  'SIPLigCel',  'SIPrhizosphere', 'RefSoil']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROKKA annotation tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Avena_rhizosphere\n",
      "Running: biocharSIP\n",
      "Running: DeepSIP\n"
     ]
    }
   ],
   "source": [
    "for study in study_list:\n",
    "    print('Running: ' + study)\n",
    "    annotation_df = pd.DataFrame()\n",
    "    for genome in os.listdir(os.path.join(workdir, 'prokka_output', study)):\n",
    "        sub_annotation = pd.read_csv(os.path.join(workdir, 'prokka_output', study, genome, genome + '.prokka.tsv'), sep='\\t')\n",
    "        sub_annotation['genome_file'] = genome\n",
    "        sub_annotation['study'] = study\n",
    "        annotation_df = annotation_df.append(sub_annotation, ignore_index=True)\n",
    "    annotation_df.to_csv(os.path.join(workdir, 'full_study_files', study + '_annotations.txt'), header=True, index=False, sep='\\t')\n",
    "    annotation_df = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transmembrane domain tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in study_list:\n",
    "    print('Running: ' + study)\n",
    "    annotation_df = pd.DataFrame()\n",
    "    for genome in os.listdir(os.path.join(workdir, 'TMHMM_output', study)):\n",
    "        sub_annotation = pd.read_csv(os.path.join(workdir, 'TMHMM_output', study, genome), sep='\\t',\n",
    "                                     names = ['locus_tag', 'length', 'ExpAA', ' First60', 'PredHel', 'Topology'])\n",
    "        sub_annotation['genome_file'] = re.sub('.prokka.faa.tmhmm$', '', genome)\n",
    "        sub_annotation['study'] = study\n",
    "        annotation_df = annotation_df.append(sub_annotation, ignore_index=True)\n",
    "    annotation_df.to_csv(os.path.join(workdir, 'full_study_files', study + '_TMHMM_output.txt'), header=True, index=False, sep='\\t')\n",
    "    annotation_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antismash cluster tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in study_list:\n",
    "    print('Running: ' + study)\n",
    "    with open(os.path.join(workdir, 'full_study_files', study + '_antismash_output.txt'), 'w') as outfile:\n",
    "        outfile.write('study\\tgenome_file\\tSMBC_product\\tSMBC_start\\tSMBC_end\\n')\n",
    "        for genome in os.listdir(os.path.join(workdir, 'antismash_output', study)):\n",
    "            BCG_records = SeqIO.parse(os.path.join(workdir, 'antismash_output', study, genome, re.sub('.antismash$', '', genome)), 'genbank')\n",
    "            for record in BCG_records:\n",
    "                for feature in record.features:\n",
    "                    if feature.type == 'region':\n",
    "                        outfile.write('\\t'.join([study,\n",
    "                                                 re.sub('.prokka.gbk.antismash$', '', genome),\n",
    "                                                 feature.qualifiers['product'][0],\n",
    "                                                 str(feature.location.start),\n",
    "                                                 str(feature.location.end) + '\\n']))\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antismash cluster tables with gene counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Avena_rhizosphere\n",
      "Running: biocharSIP\n",
      "Running: DeepSIP\n",
      "Running: rainfall\n",
      "Running: SIPLigCel\n",
      "Running: SIPrhizosphere\n",
      "Running: RefSoil\n"
     ]
    }
   ],
   "source": [
    "for study in study_list:\n",
    "    print('Running: ' + study)\n",
    "    with open(os.path.join(workdir, 'full_study_files', study + '_antismash_nGene_output.txt'), 'w') as outfile:\n",
    "        outfile.write('study\\tgenome_file\\tSMBC_region\\tSMBC_product\\tSMBC_genelocus\\n')\n",
    "        for genome in os.listdir(os.path.join(workdir, 'antismash_output', study)):\n",
    "            region_list = [f for f in os.listdir(os.path.join(workdir, 'antismash_output', study, genome)) if re.search('region.*.gbk', f)]\n",
    "            for region_gbk in region_list:\n",
    "                BCG_records = SeqIO.parse(os.path.join(workdir, 'antismash_output', study, genome, region_gbk), 'genbank')\n",
    "                for record in BCG_records:\n",
    "                    for feature in record.features:\n",
    "                        if feature.type == 'region':\n",
    "                            region_prod = feature.qualifiers['product'][0]\n",
    "                    for feature in record.features:\n",
    "                        if feature.type == \"CDS\":\n",
    "                            outfile.write('\\t'.join([study,\n",
    "                                                     re.sub('.prokka.gbk.antismash$', '', genome),\n",
    "                                                     re.sub('.gbk', '', region_gbk),\n",
    "                                                     region_prod,\n",
    "                                                     feature.qualifiers['locus_tag'][0] + '\\n']))\n",
    "                    \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepTfactor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in study_list:\n",
    "    print('Running: ' + study)\n",
    "    annotation_df = pd.DataFrame()\n",
    "    for genome in os.listdir(os.path.join(workdir, 'deepTfactor_output', study)):\n",
    "        sub_annotation = pd.read_csv(os.path.join(workdir, 'deepTfactor_output', study, genome, 'prediction_result.txt'), sep='\\t')\n",
    "        sub_annotation['genome_file'] = re.sub('.prokka.faa.TF_results$', '', genome)\n",
    "        sub_annotation['study'] = study\n",
    "        annotation_df = annotation_df.append(sub_annotation, ignore_index=True)\n",
    "    annotation_df.to_csv(os.path.join(workdir, 'full_study_files', study + '_deepTfactor_output.txt'), header=True, index=False, sep='\\t')\n",
    "    annotation_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
